{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Cybersickness from postural data with Machine Learning\n",
    "According to the postural instability theory, cybersickness occurs due to changes in the natural postural behavior of the human body.\n",
    "\n",
    "\n",
    "<a id=\"0\"></a> <br>\n",
    " ## Table of Contents  \n",
    "1. [Making the dataframes](#1)     \n",
    "1. [The Datasets](#2) \n",
    "1. [Business Understanding](#3)\n",
    "    1. [Business Questions](#4)\n",
    "1. [Data Understanding](#5)\n",
    "1. [Data Preparation - Initial NaN processing](#6)     \n",
    "1. [Questions 1 and 2](#7)     \n",
    "    1. [Data preparation](#8)\n",
    "        1. [Answering question #1](#9)   \n",
    "        1. [Answering question #2](#10)     \n",
    "1. [Question 3: What is the vibe of each neighborhood based on the neighborhood overview?](#11)\n",
    "    1. [Data Preparation](#12)     \n",
    "    1. [Modeling](#13)\n",
    "    1. [Evaluation - Answering the question](#14)\n",
    "1. [Question 4: Can we predict the price of Boston Airbnbs?](#15)\n",
    "    1. [Data Preparation](#16)     \n",
    "    1. [Modeling and Evaluation](#17)\n",
    "    1. [Answering the question](#18)\n",
    "1. [Conclusion](#19)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## Making the dataframes\n",
    "\n",
    "Since we have data coming from two different places and in different formats, we need to analyze them differently. Firstly, I will create a dataframe containing data from each experiment and then combine them. This will require some data wrangling. The goal is to create a single dataframe that contains all the data we need in the same format. \n",
    "Also, in total we have three experiments. We will import their data next."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from collections import defaultdict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty dictionary to store individual data\n",
    "dataset=defaultdict(list)\n",
    "\n",
    "#Directory with the data\n",
    "path = \"data/exp_1/APAL 2019 Force Plate Data\"\n",
    "\n",
    "for dir in os.listdir(path):\n",
    "    #importing individual data\n",
    "    postural_data = pd.read_excel(os.path.join(path, dir))\n",
    "\n",
    "    #Extracting the experimental condition label\n",
    "    condition = label = postural_data.iloc[0,0]\n",
    "\n",
    "    #Deleting the first unnecessary column\n",
    "    postural_data = postural_data.iloc[:, 1:]\n",
    "\n",
    "    #subsetting by direction of movement\n",
    "    ML_data = pd.Series(postural_data.iloc[:, 0])\n",
    "    AP_data = pd.Series(postural_data.iloc[:, 1])\n",
    "\n",
    "    #Putting the data into the same row\n",
    "\n",
    "    combined = pd.DataFrame(columns=range(6000))\n",
    "    try:\n",
    "        combined.loc[0, :2999] = ML_data.values\n",
    "        combined.loc[0, 3000:] = AP_data.values\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    #Changing the column names\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0      1      2      3      4     5      6      7      8      9  ...   \n",
      "0 -0.644 -0.645 -0.646 -0.646 -0.631 -0.63 -0.637 -0.644 -0.637 -0.615  ...  \\\n",
      "\n",
      "   5990  5991  5992  5993  5994  5995  5996  5997  5998  5999  \n",
      "0  2990  2991  2992  2993  2994  2995  2996  2997  2998  2999  \n",
      "\n",
      "[1 rows x 6000 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0    1    2    3    4    5    6    7    8    9     ...  5990  5991  5992   \n",
      "0    0    1    2    3    4    5    6    7    8    9  ...  2990  2991  2992  \\\n",
      "\n",
      "   5993  5994  5995  5996  5997  5998  5999  \n",
      "0  2993  2994  2995  2996  2997  2998  2999  \n",
      "\n",
      "[1 rows x 6000 columns]\n"
     ]
    }
   ],
   "source": [
    "print(combined)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
